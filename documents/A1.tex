\documentclass[12pt]{article}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\newcommand{\code}[1]{\texttt{#1}}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=2.5cm,rmargin=2.5cm,footskip=1cm}


\begin{document}

\begin{center}
\textbf{\large{}CS 444 - Lexical and syntactic analysis phase}
\end{center}

\begin{flushleft}
dburgoyn \textbf{\hfill{}} Section 001 \\
udimitri \textbf{\hfill{}} 2015-01-13 \\
x2fang \\
\end{flushleft}

% Main body begins here

This document describes the design phase of our compiler, discusses challenges that we encountered and how we tried to overcome them, and explains the testing that we did before submitting to Marmoset.

\section{Scanning}

We wrote a lexical scanner based on Brzozowski's ideas that were presented in class.  Our \code{Regex} class contains functionality to compute Brzozowski derivatives using structural recursion, and to test whether a regular expression is equivalent to the empty set.  We found a paper online ("Regular-expression derivatives reexamined" by Scott Owens et al.) which describes a method for converting a regular expression into an equivalent DFA using Brzozowski's ideas.  The paper also explored the idea of character equivalence classes that was hinted at in lecture, as well as a list of regular expression equivalence rules.  We adapted these ideas for use in our scanner.

We constructed a regular expression for each Joos 1W lexical token.  We encountered difficulty constructing some of these, such as the regular expressions for C-style and Javadoc comments, because these were defined using mutually-recursive productions in the lexical grammar and while our construction supported referencing previously-defined regexes in a given regex, it did not support mutual references between regexes.

Our scanner works by iteratively computing the Brzozowski derivative of each of these lexical regexes with respect to the input program, character by character, until all derivatives become equivalent to the empty set.  At this point, we determine which lexical regex matched the longest prefix of the input, and consume that longest prefix as a token of the corresponding type.  Since we do not use a line-by-line scanning approach, we must perform careful arithmetic to record accurate positional information in each lexical token.

We tested the scanner against a few valid inputs before beginning work on the parser.

\section{Parsing}

To facilitate debugging, we built a human-readable description of a context-free approximation to Joos 1W's syntactic grammar by reading the relevant sections of the Java Language Specification 2.0.  We then wrote a tool to convert this human-readable grammar into a CS 241-style .cfg file, which we fed into the provided parse table generator to build an LR(1) parse table.

Our parser reads the LR(1) parse table and stores its terminals, non-terminals, start symbol and productions in internal data structures.  It then uses the standard LR(1) algorithm to produce a parse tree from the stream of lexical tokens produced by the scanner.  If no transition exists given the current state and input token at any point in the parse, the parser reports the unexpected token along with its positional information for debugging purposes.

We tested the parser against a few valid inputs (produced by our scanner) before beginning work on the weeder.

\section{Weeding}

TODO: Describe the weeding process.

Once the weeder was largely complete, we began to test our compiler as a whole.

\section{Testing}

TODO: Describe the testing process.

In the early phases of this assignment, we have fed a small amount of ad-hoc Joos source to the scanner in order to test its correctness. Afterwards, it was only once our Joos grammar file had grown to encompass most of the language, and would furthermore successully generate an LR(1) parse table, that we began to rigorously test the parser.

Initially we had created a set of test input files based on the Joos 1W features page from the course website. The examples given there were saved in their own files, with necessary modifications made, such as renaming the public class to match its file name, or adding a constructor. To automate the testing of these cases, we created \tt{RunParserTests.java}, which runs the compiler on each test file, reporting if the compiler accepted or failed to accept the file as expected. 

After the grammar and weeder were developed enough to pass these initial test cases, we downloaded the public Marmoset tests and used them with \tt{RunParserTests.java}, which provided the basis of the rest of our testing. We would typically run the tests, and if we noticed that one of them failed, then we would focus on making the changes required to make the test pass.


\end{document}
